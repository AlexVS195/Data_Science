{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVA-31fUXNNw",
        "outputId": "280688cf-b436-4dda-fbfa-434ae353d9ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.7.4)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj9sZMnlGyuy",
        "outputId": "214fea32-0f63-4a6b-b2eb-1c8475a4a246"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.5154 - accuracy: 0.8146 - val_loss: 0.4145 - val_accuracy: 0.8559 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.3781 - accuracy: 0.8605 - val_loss: 0.3823 - val_accuracy: 0.8660 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "938/938 [==============================] - 3s 4ms/step - loss: 0.3440 - accuracy: 0.8744 - val_loss: 0.3588 - val_accuracy: 0.8709 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "938/938 [==============================] - 3s 4ms/step - loss: 0.3218 - accuracy: 0.8809 - val_loss: 0.3615 - val_accuracy: 0.8702 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.3044 - accuracy: 0.8871 - val_loss: 0.3395 - val_accuracy: 0.8760 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.2893 - accuracy: 0.8920 - val_loss: 0.3305 - val_accuracy: 0.8793 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "938/938 [==============================] - 3s 4ms/step - loss: 0.2800 - accuracy: 0.8950 - val_loss: 0.3271 - val_accuracy: 0.8827 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "938/938 [==============================] - 3s 4ms/step - loss: 0.2717 - accuracy: 0.8982 - val_loss: 0.3340 - val_accuracy: 0.8794 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.2609 - accuracy: 0.9019 - val_loss: 0.3374 - val_accuracy: 0.8834 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "938/938 [==============================] - 3s 4ms/step - loss: 0.2549 - accuracy: 0.9031 - val_loss: 0.3272 - val_accuracy: 0.8816 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.2459 - accuracy: 0.9069 - val_loss: 0.3217 - val_accuracy: 0.8886 - lr: 0.0010\n",
            "Epoch 12/30\n",
            "938/938 [==============================] - 3s 4ms/step - loss: 0.2044 - accuracy: 0.9230 - val_loss: 0.2963 - val_accuracy: 0.8969 - lr: 1.0000e-04\n",
            "Epoch 13/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.1944 - accuracy: 0.9266 - val_loss: 0.2955 - val_accuracy: 0.8973 - lr: 1.0000e-05\n",
            "Epoch 14/30\n",
            "938/938 [==============================] - 3s 4ms/step - loss: 0.1931 - accuracy: 0.9263 - val_loss: 0.2955 - val_accuracy: 0.8973 - lr: 1.0000e-06\n",
            "Epoch 15/30\n",
            "938/938 [==============================] - 3s 4ms/step - loss: 0.1942 - accuracy: 0.9261 - val_loss: 0.2955 - val_accuracy: 0.8974 - lr: 1.0000e-07\n",
            "Epoch 16/30\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.1930 - accuracy: 0.9259 - val_loss: 0.2955 - val_accuracy: 0.8974 - lr: 1.0000e-08\n",
            "Epoch 17/30\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.1929 - accuracy: 0.9270 - val_loss: 0.2955 - val_accuracy: 0.8974 - lr: 1.0000e-09\n",
            "Epoch 18/30\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.1927 - accuracy: 0.9271 - val_loss: 0.2955 - val_accuracy: 0.8974 - lr: 1.0000e-10\n",
            "Epoch 19/30\n",
            "938/938 [==============================] - 3s 4ms/step - loss: 0.1930 - accuracy: 0.9263 - val_loss: 0.2955 - val_accuracy: 0.8974 - lr: 1.0000e-11\n",
            "Epoch 20/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.1941 - accuracy: 0.9263 - val_loss: 0.2955 - val_accuracy: 0.8974 - lr: 1.0000e-12\n",
            "Epoch 21/30\n",
            "938/938 [==============================] - 3s 4ms/step - loss: 0.1935 - accuracy: 0.9269 - val_loss: 0.2955 - val_accuracy: 0.8974 - lr: 1.0000e-13\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2955 - accuracy: 0.8974\n",
            "Точність на тестових даних: 0.8974000215530396\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "\n",
        "# Завантажуємо датасет Fashion MNIST\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Нормалізуємо дані\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Перетворюємо мітки в категоріальний формат\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Створюємо модель\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),  # Вхідний шар\n",
        "    Dense(256, activation='relu'),  # Прихований шар з 256 нейронами та функцією активації ReLU\n",
        "    Dropout(0.1),  # Техніка регуляризації Dropout\n",
        "    Dense(128, activation='relu'),  # Прихований шар з 128 нейронами\n",
        "    Dropout(0.1),  # Техніка регуляризації Dropout\n",
        "    Dense(10, activation='softmax')  # Вихідний шар з 10 нейронами та функцією активації Softmax\n",
        "])\n",
        "\n",
        "# Компілюємо модель\n",
        "# model.compile(optimizer=RMSprop(learning_rate=0.001),\n",
        "#               loss='categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# model.compile(optimizer=SGD(learning_rate=0.001, momentum=0.9),\n",
        "#               loss='categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# Рання зупинка\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Планувальник швидкості навчання\n",
        "def lr_scheduler(epoch, lr):\n",
        "    if epoch > 10:\n",
        "        return lr * 0.1\n",
        "    return lr\n",
        "\n",
        "lr_schedule = LearningRateScheduler(lr_scheduler)\n",
        "\n",
        "# Навчаємо модель\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=64,\n",
        "                    epochs=30,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=[early_stopping, lr_schedule])\n",
        "\n",
        "# Оцінюємо точність моделі на тестових даних\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Точність на тестових даних: {test_acc}')"
      ]
    }
  ]
}